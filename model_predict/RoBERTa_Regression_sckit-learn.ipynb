{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4c6badb-af48-4350-af16-5652ac3498b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No normalization for SPS. Feature removed!\n",
      "No normalization for AvgIpc. Feature removed!\n",
      "Skipped loading some Tensorflow models, missing a dependency. No module named 'tensorflow'\n",
      "Skipped loading modules with pytorch-geometric dependency, missing a dependency. No module named 'torch_geometric'\n",
      "Skipped loading modules with pytorch-geometric dependency, missing a dependency. cannot import name 'DMPNN' from 'deepchem.models.torch_models' (/HDD1/bbq9088/miniconda3/envs/molberta/lib/python3.10/site-packages/deepchem/models/torch_models/__init__.py)\n",
      "Skipped loading modules with pytorch-lightning dependency, missing a dependency. No module named 'lightning'\n",
      "Skipped loading some Jax models, missing a dependency. No module named 'jax'\n",
      "Skipped loading some PyTorch models, missing a dependency. No module named 'tensorflow'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from transformers import RobertaTokenizer, RobertaModel\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import Descriptors, Crippen, Lipinski, Fragments, rdMolDescriptors\n",
    "import deepchem as dc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "48ad24e5-2c9f-4e70-8551-54fb6d7674f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Move model to GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c7483406-c052-428e-bc7a-e08a13265ffe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/HDD1/bbq9088/miniconda3/envs/molberta/lib/python3.10/site-packages/transformers/modeling_utils.py:442: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(checkpoint_file, map_location=\"cpu\")\n",
      "Some weights of the model checkpoint at ./origin_model/roberta were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# Load RoBERTa model and tokenizer\n",
    "tokenizer = RobertaTokenizer.from_pretrained(\"./origin_model/roberta/tokenizer_folder\")\n",
    "model = RobertaModel.from_pretrained(\"./origin_model/roberta\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ff9d3ef-4fa2-4d53-9fcb-abc87f99b224",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CircularFingerprint for dataset featurization\n",
    "featurizer = dc.feat.CircularFingerprint(radius=2, size=2048)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d583987f-228d-45c5-868d-9f218cad152b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets\n",
    "tasks_freesolv, datasets_freesolv, _ = dc.molnet.load_freesolv(featurizer=featurizer, splitter=None, transformers=[], reload=True)\n",
    "dataset_freesolv = datasets_freesolv[0]\n",
    "df_freesolv = pd.DataFrame({'smiles': dataset_freesolv.ids, 'label': dataset_freesolv.y[:, 0]}).dropna()\n",
    "\n",
    "tasks_lipo, datasets_lipo, _ = dc.molnet.load_lipo(featurizer=featurizer, splitter=None, transformers=[], reload=True)\n",
    "dataset_lipo = datasets_lipo[0]\n",
    "df_lipo = pd.DataFrame({'smiles': dataset_lipo.ids, 'label': dataset_lipo.y[:, 0]}).dropna()\n",
    "\n",
    "tasks_esol, datasets_esol, _ = dc.molnet.load_delaney(featurizer=featurizer, splitter=None, transformers=[], reload=True)\n",
    "dataset_esol = datasets_esol[0]\n",
    "df_esol = pd.DataFrame({'smiles': dataset_esol.ids, 'label': dataset_esol.y[:, 0]}).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b2d5a5d9-4a83-4c3b-94b3-5108c490a520",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate molecular properties\n",
    "def calculate_properties(smiles):\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    properties = []\n",
    "    try:\n",
    "        properties.append(Descriptors.MolWt(mol) if mol else None)\n",
    "        properties.append(Crippen.MolLogP(mol) if mol else None)\n",
    "        properties.append(Descriptors.TPSA(mol) if mol else None)\n",
    "        properties.append(Lipinski.NumHAcceptors(mol) if mol else None)\n",
    "        properties.append(Lipinski.NumHDonors(mol) if mol else None)\n",
    "        properties.append(Lipinski.NumRotatableBonds(mol) if mol else None)\n",
    "        properties.append(Chem.GetFormalCharge(mol) if mol else None)\n",
    "        properties.append(rdMolDescriptors.CalcNumAtomStereoCenters(mol) if mol else None)\n",
    "        properties.append(rdMolDescriptors.CalcFractionCSP3(mol) if mol else None)\n",
    "        properties.append(Descriptors.NumAliphaticCarbocycles(mol) if mol else None)\n",
    "        properties.append(Descriptors.NumAromaticRings(mol) if mol else None)\n",
    "        properties.append(Descriptors.NumHeteroatoms(mol) if mol else None)\n",
    "        properties.append(Fragments.fr_COO(mol) if mol else None)\n",
    "        properties.append(Fragments.fr_Al_OH(mol) if mol else None)\n",
    "        properties.append(Fragments.fr_alkyl_halide(mol) if mol else None)\n",
    "        properties.append(Descriptors.NumAromaticCarbocycles(mol) if mol else None)\n",
    "        properties.append(Fragments.fr_piperdine(mol) if mol else None)\n",
    "        properties.append(Fragments.fr_methoxy(mol) if mol else None)\n",
    "    except Exception as e:\n",
    "        print(f\"Warning: Could not calculate properties for SMILES: {smiles}. Error: {e}\")\n",
    "        return [None] * 18\n",
    "    return properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3283a00c-4ba6-43fa-862f-148547fc0f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create input text for SMILES\n",
    "def create_input_text(smiles):\n",
    "    properties = calculate_properties(smiles)\n",
    "    property_names = [\n",
    "        \"Molecular Weight\", \"LogP\", \"Topological Polar Surface Area\",\n",
    "        \"Number of Hydrogen Bond Acceptors\", \"Number of Hydrogen Bond Donors\",\n",
    "        \"Number of Rotatable Bonds\", \"Formal Charge\", \"Number of Atom Stereocenters\",\n",
    "        \"Fraction of sp3 Carbon Atoms\", \"Number of Aliphatic Carbocycles\",\n",
    "        \"Number of Aromatic Rings\", \"Number of Heteroatoms\", \"Number of Carboxylic Acid Groups\",\n",
    "        \"Number of Aliphatic Alcohol Groups\", \"Number of Alkyl Halide Groups\",\n",
    "        \"Number of Aromatic Carbocycles\", \"Number of Piperidine Groups\",\n",
    "        \"Number of Methoxy Groups\"\n",
    "    ]\n",
    "    properties_text = \" | \".join(\n",
    "        [f\"{name}: {value:.5f}\" if value is not None else f\"{name}: None\"\n",
    "         for name, value in zip(property_names, properties)]\n",
    "    )\n",
    "    input_text = f\"SMILES: {smiles} | {properties_text}\"\n",
    "    return input_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4fbdd138-28da-4c75-9bd3-ba0b3e3e749c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get embeddings using RoBERTa\n",
    "def get_embeddings(model, tokenizer, smiles_list):\n",
    "    embeddings = []\n",
    "    for smiles in tqdm(smiles_list, desc=\"Processing SMILES with Roberta\"):\n",
    "        input_text = create_input_text(smiles)\n",
    "        inputs = tokenizer(input_text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512).to(device)\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "        embedding = outputs.last_hidden_state.mean(dim=1).cpu().numpy().flatten()\n",
    "        embeddings.append(embedding)\n",
    "    return np.array(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "235ee945-c692-4f12-bca7-038680b6d14d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ridge regression with K-Fold cross-validation\n",
    "def train_and_evaluate_regression_kfold(X, y, n_splits=5):\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    rmse_scores = []\n",
    "    r2_scores = []\n",
    "\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        model = Ridge()\n",
    "        model.fit(X_train, y_train.ravel())\n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "        # Z-score standardization\n",
    "        y_test_mean, y_test_std = np.mean(y_test), np.std(y_test)\n",
    "        y_test_z = (y_test - y_test_mean) / y_test_std\n",
    "        y_pred_z = (y_pred - y_test_mean) / y_test_std\n",
    "\n",
    "        # Metrics\n",
    "        rmse_scores.append(np.sqrt(mean_squared_error(y_test_z, y_pred_z)))\n",
    "        r2_scores.append(r2_score(y_test_z, y_pred_z))\n",
    "\n",
    "    print(f\"Average RMSE: {np.mean(rmse_scores):.4f} ± {np.std(rmse_scores):.4f}\")\n",
    "    print(f\"Average R²: {np.mean(r2_scores):.4f} ± {np.std(r2_scores):.4f}\")\n",
    "    return rmse_scores, r2_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d1881a67-fbef-4900-a469-4464b14f4056",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset processing and evaluation\n",
    "embedding_dir = os.path.join(os.getcwd(), 'Embedding')\n",
    "result_dir = os.path.join(os.getcwd(), 'Result/Properties')\n",
    "os.makedirs(embedding_dir, exist_ok=True)\n",
    "os.makedirs(result_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7c1e58d0-6e09-42f8-b9dd-20a1572d85e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Processing FreeSolv ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing SMILES with Roberta: 100%|████████████████████████████████████████████| 642/642 [00:06<00:00, 99.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved embeddings to /HDD1/bbq9088/GPT-MolBERTa/model_predict/Embedding/FreeSolv_roberta_embeddings.csv\n",
      "Average RMSE: 0.4428 ± 0.0453\n",
      "Average R²: 0.8019 ± 0.0403\n",
      "Results for FreeSolv saved to /HDD1/bbq9088/GPT-MolBERTa/model_predict/Result/Properties/FreeSolv_regression_results.txt\n",
      "\n",
      "=== Processing Lipophilicity ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing SMILES with Roberta: 100%|██████████████████████████████████████████| 4200/4200 [00:43<00:00, 97.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved embeddings to /HDD1/bbq9088/GPT-MolBERTa/model_predict/Embedding/Lipophilicity_roberta_embeddings.csv\n",
      "Average RMSE: 0.7820 ± 0.0067\n",
      "Average R²: 0.3885 ± 0.0105\n",
      "Results for Lipophilicity saved to /HDD1/bbq9088/GPT-MolBERTa/model_predict/Result/Properties/Lipophilicity_regression_results.txt\n",
      "\n",
      "=== Processing ESOL ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing SMILES with Roberta: 100%|█████████████████████████████████████████| 1128/1128 [00:11<00:00, 102.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved embeddings to /HDD1/bbq9088/GPT-MolBERTa/model_predict/Embedding/ESOL_roberta_embeddings.csv\n",
      "Average RMSE: 0.4905 ± 0.0365\n",
      "Average R²: 0.7580 ± 0.0355\n",
      "Results for ESOL saved to /HDD1/bbq9088/GPT-MolBERTa/model_predict/Result/Properties/ESOL_regression_results.txt\n"
     ]
    }
   ],
   "source": [
    "for dataset_name, df in [(\"FreeSolv\", df_freesolv), (\"Lipophilicity\", df_lipo), (\"ESOL\", df_esol)]:\n",
    "    print(f\"\\n=== Processing {dataset_name} ===\")\n",
    "\n",
    "    # SMILES embedding\n",
    "    embeddings = get_embeddings(model, tokenizer, df['smiles'].tolist())\n",
    "    embedding_file = os.path.join(embedding_dir, f\"{dataset_name}_roberta_embeddings.csv\")\n",
    "    pd.DataFrame(embeddings).to_csv(embedding_file, index=False)\n",
    "    print(f\"Saved embeddings to {embedding_file}\")\n",
    "\n",
    "    # Regression evaluation\n",
    "    labels = df['label'].values\n",
    "    rmse_scores, r2_scores = train_and_evaluate_regression_kfold(embeddings, labels)\n",
    "\n",
    "    # Save results\n",
    "    result_file = os.path.join(result_dir, f\"{dataset_name}_regression_results.txt\")\n",
    "    with open(result_file, 'w') as f:\n",
    "        f.write(f\"Dataset: {dataset_name}\\n\")\n",
    "        f.write(f\"Average RMSE: {np.mean(rmse_scores):.4f} ± {np.std(rmse_scores):.4f}\\n\")\n",
    "        f.write(f\"Average R²: {np.mean(r2_scores):.4f} ± {np.std(r2_scores):.4f}\\n\")\n",
    "\n",
    "    print(f\"Results for {dataset_name} saved to {result_file}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
